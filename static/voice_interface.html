<!DOCTYPE html>
<html>
<head>
    <title>NLWeb Voice Interface</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
        .voice-container { text-align: center; margin: 40px 0; }
        .voice-button { 
            width: 150px; height: 150px; border-radius: 50%; 
            border: none; font-size: 18px; cursor: pointer;
            transition: all 0.3s ease;
        }
        .voice-button.listening { background: #ff4444; color: white; }
        .voice-button.idle { background: #4CAF50; color: white; }
        .conversation { max-height: 400px; overflow-y: auto; border: 1px solid #ddd; padding: 20px; margin: 20px 0; }
        .message { margin: 10px 0; padding: 10px; border-radius: 5px; }
        .user-message { background: #e3f2fd; text-align: right; }
        .ai-message { background: #f1f8e9; text-align: left; }
    </style>
</head>
<body>
    <h1>NLWeb Voice Assistant</h1>
    
    <div class="voice-container">
        <button id="voiceButton" class="voice-button idle" onclick="toggleVoice()">
            Click to Speak
        </button>
        <p id="status">Ready to listen</p>
    </div>
    
    <div id="conversation" class="conversation"></div>
    
    <script>
        let isListening = false;
        let recognition;
        let synthesis = window.speechSynthesis;
        
        // Initialize speech recognition
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = false;
            recognition.interimResults = false;
            recognition.lang = 'en-US';
            
            recognition.onstart = function() {
                isListening = true;
                updateUI();
            };
            
            recognition.onresult = function(event) {
                const transcript = event.results[0][0].transcript;
                addMessage(transcript, 'user');
                queryNLWeb(transcript);
            };
            
            recognition.onend = function() {
                isListening = false;
                updateUI();
            };
            
            recognition.onerror = function(event) {
                console.error('Speech recognition error:', event.error);
                isListening = false;
                updateUI();
            };
        }
        
        function toggleVoice() {
            if (isListening) {
                recognition.stop();
            } else {
                recognition.start();
            }
        }
        
        function updateUI() {
            const button = document.getElementById('voiceButton');
            const status = document.getElementById('status');
            
            if (isListening) {
                button.className = 'voice-button listening';
                button.textContent = 'Listening...';
                status.textContent = 'Speak now';
            } else {
                button.className = 'voice-button idle';
                button.textContent = 'Click to Speak';
                status.textContent = 'Ready to listen';
            }
        }
        
        function addMessage(text, sender) {
            const conversation = document.getElementById('conversation');
            const message = document.createElement('div');
            message.className = `message ${sender}-message`;
            message.textContent = text;
            conversation.appendChild(message);
            conversation.scrollTop = conversation.scrollHeight;
        }
        
        async function queryNLWeb(question) {
            try {
                const response = await fetch('/api/ask', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ question: question })
                });
                
                const result = await response.json();
                const answer = result.answer || 'Sorry, I could not find an answer.';
                
                addMessage(answer, 'ai');
                speakText(answer);
                
            } catch (error) {
                console.error('Error querying NLWeb:', error);
                const errorMsg = 'Sorry, I encountered an error processing your request.';
                addMessage(errorMsg, 'ai');
                speakText(errorMsg);
            }
        }
        
        function speakText(text) {
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 0.8;
            utterance.pitch = 1;
            synthesis.speak(utterance);
        }
    </script>
</body>
</html>
